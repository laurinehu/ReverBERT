{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/2020-09-08_sentences.txt\") as sfile:\n",
    "    sents = sfile.readlines()\n",
    "sents = [x.replace(\"\\n\", \"\") for x in sents]\n",
    "\n",
    "with open(\"data/2020-09-14_embeddings_mean.csv\") as efile:\n",
    "    embs = efile.readlines()\n",
    "embs = [[float(y) for y in x.replace(\"\\n\", \"\").split(\";\")] for x in embs]\n",
    "\n",
    "with open(\"data/2020-09-22_properties.csv\") as pfile:\n",
    "    props = pfile.readlines()\n",
    "props = [[int(y) for y in x.replace(\"\\n\", \"\").split(\";\")] for x in props]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "X, y = np.array(props), np.array(embs)\n",
    "# summarize shape\n",
    "print(X.shape, y.shape)\n",
    "inputdim = X.shape[1]\n",
    "outputdim = y.shape[1]\n",
    "print(inputdim)\n",
    "print(outputdim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(inputdim, outputdim)     # define the network\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(props, embs, test_size=0.20, random_state=42)\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "for t in range(2000):\n",
    "    prediction = net(X_train)     # input x and predict based on x\n",
    "    loss = loss_func(prediction, y_train)     # must be (1. nn output, 2. target)\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emptymodel = Net(inputdim, outputdim)\n",
    "model = my_load_model(\"test\", emptymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model_rf = RandomForestRegressor(n_estimators=200)\n",
    "# fit model\n",
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.sort(model_rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features names in right order\n",
    "names = ['Same-Unit', 'elaboration-additional-e', 'List', 'elaboration-object-attribute-e',\n",
    "                'condition', 'attribution', 'elaboration-additional', 'circumstance',\n",
    "                'purpose', 'elaboration-general-specific', 'restatement-e', 'reason',\n",
    "                'elaboration-part-whole-e', 'rhetorical-question', 'manner', 'concession',\n",
    "                'consequence-n', 'temporal-same-time', 'restatement', 'elaboration-object-attribute',\n",
    "                'antithesis', 'consequence-s', 'definition', 'Contrast', 'result', 'means', 'attribution-n',\n",
    "                'interpretation-s', 'temporal-after', 'example-e', 'result-e', 'explanation-argumentative',\n",
    "                'elaboration-general-specific-e', 'elaboration-set-member-e', 'attribution-e',\n",
    "                'evaluation-s', 'circumstance-e', 'background', 'evidence', 'comment-e', 'purpose-e',\n",
    "                'interpretation-n', 'condition-e', 'temporal-before', 'comment', 'elaboration-part-whole',\n",
    "                'comparison', 'contingency', 'hypothetical', 'analogy-e', 'evaluation-s-e',\n",
    "                'elaboration-set-member', 'temporal-after-e', 'comparison-e', 'means-e', 'example',\n",
    "                'evidence-e', 'cause', 'preference', 'enablement', 'question-answer-s',\n",
    "                'explanation-argumentative-e', 'definition-e', 'antithesis-e', 'summary-n',\n",
    "                'analogy', 'interpretation-s-e', 'concession-e', 'consequence-s-e', 'manner-e',\n",
    "                'preference-e', 'reason-e', 'temporal-same-time-e', 'consequence-n-e',\n",
    "                'enablement-e', 'evaluation-n', 'temporal-before-e', 'otherwise', 'question-answer-n',\n",
    "                'conclusion', 'dr_exist', 'nb_distinct_rel', 'nb_nuc', 'nb_sat', 'nb_root'\n",
    "                'width', \"height\", \"multinuc\"]\n",
    "\n",
    "feat_imp = model_rf.feature_importances_\n",
    "    \n",
    "sVals = sorted(feat_imp)  \n",
    "Z = [x for _,x in sorted(zip(feat_imp,names))]\n",
    "for feat, name in zip(sVals, Z):\n",
    "    print(str(feat)+\"  \"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.sort(model_rf.feature_importances_)\n",
    "plt.plot(l)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rf = model_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FImp import rsqq, rsq, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_dists = []\n",
    "rsq_dists = []\n",
    "mse_dists = []\n",
    "\n",
    "for true, pred in zip(preds_rf, y_test):\n",
    "    cos_dists.append(distance.cosine(true, pred))\n",
    "    rsq_dists.append(rsqq(true, pred))\n",
    "    mse_dists.append(mse(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(rsq_dists))\n",
    "print(np.mean(rsq_dists))\n",
    "print(np.max(rsq_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(rsq_dists))\n",
    "print(np.mean(rsq_dists))\n",
    "print(np.max(rsq_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(cos_dists))\n",
    "print(np.mean(cos_dists))\n",
    "print(np.max(cos_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(mse_dists))\n",
    "print(np.mean(mse_dists))\n",
    "print(np.max(mse_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in zip(preds_rf[0], y_test[0]):\n",
    "    print(str(x)+\"   \"+str(float(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_dists = []\n",
    "rsq_dists = []\n",
    "\n",
    "\n",
    "for true, pred in zip(preds_rf, y_test):\n",
    "    #cos_dists.append(distance.cosine(true, pred))\n",
    "    rsq_dists.append(rsqq(true, pred))\n",
    "\n",
    "\n",
    "print(np.min(rsq_dists))\n",
    "print(np.mean(rsq_dists))\n",
    "print(np.max(rsq_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FImp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X = net(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X = pred_X.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mse = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in zip(y_test, pred_X):\n",
    "    x = [int(b) for b in x]\n",
    "    y = [int(a) for a in y]\n",
    "    cur_mse = mse(list(x), list(y))\n",
    "    mean_mse.append(cur_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mae = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in zip(y_test, pred_X):\n",
    "    x = [int(b) for b in x]\n",
    "    y = [int(a) for a in y]\n",
    "    cur_mae = mae(list(x), list(y))\n",
    "    mean_mae.append(cur_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(mean_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(mean_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(mean_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(mean_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbg_pred = pred_X[100]\n",
    "dbg_true = y_test[100]\n",
    "\n",
    "\n",
    "print(mse(dbg_pred, dbg_true))\n",
    "print(\"===============\")\n",
    "for x, y in zip(dbg_pred, dbg_true):\n",
    "    print(str(x)+ \"\\t\"+ str(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_disc_all",
   "language": "python",
   "name": "venv_disc_all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

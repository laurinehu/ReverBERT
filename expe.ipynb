{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/2020-09-08_sentences.txt\") as sfile:\n",
    "    sents = sfile.readlines()\n",
    "sents = [x.replace(\"\\n\", \"\") for x in sents]\n",
    "\n",
    "with open(\"data/2020-09-14_embeddings_mean.csv\") as efile:\n",
    "    embs = efile.readlines()\n",
    "embs = [[float(y) for y in x.replace(\"\\n\", \"\").split(\";\")] for x in embs]\n",
    "\n",
    "with open(\"data/2020-09-22_properties.csv\") as pfile:\n",
    "    props = pfile.readlines()\n",
    "props = [[int(y) for y in x.replace(\"\\n\", \"\").split(\";\")] for x in props]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6200, 87) (6200, 768)\n",
      "87\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "# create dataset\n",
    "X, y = np.array(props), np.array(embs)\n",
    "# summarize shape\n",
    "print(X.shape, y.shape)\n",
    "inputdim = X.shape[1]\n",
    "outputdim = y.shape[1]\n",
    "print(inputdim)\n",
    "print(outputdim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(inputdim, outputdim)     # define the network\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(props, embs, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep for pytorch\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "for t in range(2000):\n",
    "    prediction = net(X_train)     # input x and predict based on x\n",
    "    loss = loss_func(prediction, y_train)     # must be (1. nn output, 2. target)\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emptymodel = Net(inputdim, outputdim)\n",
    "model = my_load_model(\"test\", emptymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "model_rf = RandomForestRegressor(n_estimators=50)\n",
    "# fit model\n",
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.sort(model_rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x149083d10>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiLklEQVR4nO3de3hc9X3n8fdXM7rLknWzsWXLFthczNUg7FwgaSE0EBKctqSYpInbwEPThm3abC+0T8smbPd5ym4bNk3oti6wASctsCTdmJSUQIA2zRJiGTBgHIOwLUs2tnWzLGkkze27f8wRCCHHY1vjMzP6vJ5Hj+ec8xvNV+PxR8e/8zu/n7k7IiJSvErCLkBERHJLQS8iUuQU9CIiRU5BLyJS5BT0IiJFLhp2AdM1NTX58uXLwy5DRKSgbN26tc/dm2c6lndBv3z5cjo6OsIuQ0SkoJhZ19GOqetGRKTIKehFRIqcgl5EpMgp6EVEipyCXkSkyCnoRUSKnIJeRKTIKehFRPLAff+xm3956c2cfG8FvYhIHviHH+3ihz87mJPvraAXEQnZRDLFgSPjLK2vysn3zyrozexqM9tpZp1mdtsMx8vN7KHg+HNmtjzY/ykze3HKV9rMLprdH0FEpLDtPzyOOyxtCCnozSwC3A1cA6wCbjSzVdOa3QQMuvsK4C7gTgB3/5a7X+TuFwGfBna7+4uzV76ISOHrHogBsKS+MiffP5sz+jVAp7vvcvc48CCwblqbdcD9weNHgCvNzKa1uTF4roiITNEzOAaEeEYPtADdU7Z7gn0ztnH3JDAENE5rcwPwTzO9gJndYmYdZtbR29ubTd0iIkWjezBGacQ4rbYiJ9//lFyMNbO1QMzdX5npuLtvdPd2d29vbp5xOmURkaLVPRBj8fxKIiXTO0JmRzZBvw9YOmV7SbBvxjZmFgXqgP4px9dzlLN5EZG5rntwLGcjbiC7oN8CrDSzNjMrIxPam6e12QxsCB5fDzzl7g5gZiXAr6H+eRGRGfUMxFjakJsLsZDFClPunjSzW4HHgQhwn7tvN7M7gA533wzcC2wys05ggMwvg0kfALrdfdfsly8iUthGJ5L0j8ZZksMz+qyWEnT3x4DHpu27fcrjceATR3nuM8B7TrxEEZHite9wZsRNroZWgu6MFREJ1eQY+lwNrQQFvYhIqN4K+pAvxoqISI50D45RWRqhqaYsZ6+hoBcRCVH3QIwl9ZW8ezKB2aOgFxEJUffgWE4vxIKCXkQkVD2DsZxeiAUFvYhIaIZiCYbHkzm9EAsKehGR0HQPTg6tVNeNiEhRenseep3Ri4gUpbfP6BX0IiJFqXtgjHkVUeoqS3P6Ogp6EZGQdA/Gcn4hFhT0IiKh6Rkcy/mFWFDQi4iEwt0zY+h1Ri8iUpx6RyYYT6RzfiEWFPQiIqHoHsjMQ38qum6yWnhERERO3u98aytb9gySTjsTyTSQ+zH0oKAXETkl3J0nXj3IWafN48Il8ykxo3leOSuaa3L+2lkFvZldDXyVzJqx97j7X047Xg48AFwC9AM3uPue4NgFwN8DtUAauDRYelBEZM44Mp4kkXI+flELN19++il97WP20ZtZBLgbuAZYBdxoZqumNbsJGHT3FcBdwJ3Bc6PAN4HPufu5wC8AiVmrXkSkQPSPTADQmMMFRo4mm4uxa4BOd9/l7nHgQWDdtDbrgPuDx48AV1pmFv1fAl5y920A7t7v7qnZKV1EpHD0j8YBaKwuP+WvnU3QtwDdU7Z7gn0ztnH3JDAENAJnAm5mj5vZ82b2RzO9gJndYmYdZtbR29t7vD+DiEje6x/JBH1DdX6e0Z+MKHAZ8Kngz182syunN3L3je7e7u7tzc3NOS5JROTU6x/NdN001eTnGf0+YOmU7SXBvhnbBP3ydWQuyvYA/+7ufe4eAx4DLj7ZokVECs1AcEZfX53bCcxmkk3QbwFWmlmbmZUB64HN09psBjYEj68HnnJ3Bx4HzjezquAXwAeBV2endBGRwtE/GmdeRZTyaOSUv/Yxh1e6e9LMbiUT2hHgPnffbmZ3AB3uvhm4F9hkZp3AAJlfBrj7oJl9hcwvCwcec/d/ydHPIiKSt/pH46F020CW4+jd/TEy3S5T990+5fE48ImjPPebZIZYiojMWf0jE6FciAXNdSMickoMjMZpVNCLiBSvvpF4KDdLgYJeRCTn0mlnMBYP5WYpUNCLiOTc0FiCVNrVRy8iUqwmb5ZS142ISJGanP5AXTciIkXqrQnNdEYvIlKcFPQiIkVuci76+ioFvYhIURoYjTO/qpTSSDiRq6AXEcmx/pF4aEMrQUEvIpJzfSMTNIU04gYU9CIiOTcwqjN6EZGi1j8a3jw3oKAXEcmp1OQ8NyHNRQ8KehGRnBqMxXEntCmKQUEvIpJTAyHfLAUKehGRnOoLbpbSxVgRkSI1eUYf1nqxkGXQm9nVZrbTzDrN7LYZjpeb2UPB8efMbHmwf7mZjZnZi8HX381y/SIieW1y5sowz+iPuTi4mUWAu4GrgB5gi5ltdvdXpzS7CRh09xVmth64E7ghOPaGu180u2WLiBSG/pEJzMKb5wayO6NfA3S6+y53jwMPAuumtVkH3B88fgS40sxs9soUESlM/aNx6qvKiJSEF4nZBH0L0D1luyfYN2Mbd08CQ0BjcKzNzF4ws38zs8tnegEzu8XMOsyso7e397h+ABGRfNY/Eg91aCXk/mLsm0Cru68Gvgj8o5nVTm/k7hvdvd3d25ubm3NckojIqTMQ8l2xkF3Q7wOWTtleEuybsY2ZRYE6oN/dJ9y9H8DdtwJvAGeebNEiIoWib3QitCUEJ2UT9FuAlWbWZmZlwHpg87Q2m4ENwePrgafc3c2sObiYi5mdDqwEds1O6SIi+S8fzuiPOerG3ZNmdivwOBAB7nP37WZ2B9Dh7puBe4FNZtYJDJD5ZQDwAeAOM0sAaeBz7j6Qix9ERCTfJFJpDscSoQ6thCyCHsDdHwMem7bv9imPx4FPzPC8bwPfPskaRUQK0mBscvqD/O+6ERGREzB5s1Sxj7oREZmzFPQiIkWufzQzoVnYF2MV9CIiObKrdxSAhgIYXikiIsfp6Z8d4u6nO7l8ZRP1VaWh1qKgFxGZZVu7Bvntb23lrNPm8befupiwp/5S0IuIzKLXDw7z2W9s4bTaCr7xm2uYVxHu2Two6EVEZs1QLMGG+35KWbSETTetpXleuH3zkxT0IiKz5MuPbufQ8AT3bmhnaUNV2OW8RUEvIjILfrD9AN95YR+f/8UVXLBkftjlvIOCXkTkJA2OxvnTf36FVYtq+fwvrgi7nHfJaq4bERE5uj//7isMjcXZdNMayqL5d/6cfxWJiBSQH2w/wPdeepMvXLmScxa9a12lvKCgFxE5CU/uOEhDdRmf++AZYZdyVAp6EZGT0NUfo62pmmgkf+M0fysTESkAewdiLGvMn6GUM1HQi4icoPFEigNHxlnWUB12KT+Xgl5E5AT1DMZwpzjO6M3sajPbaWadZnbbDMfLzeyh4PhzZrZ82vFWMxsxsz+YpbpFRELX1R8DoLXQg97MIsDdwDXAKuBGM1s1rdlNwKC7rwDuAu6cdvwrwPdPvlwRkfwxGfTL8mi6g5lkc0a/Buh0913uHgceBNZNa7MOuD94/AhwpQXzcprZx4HdwPZZqVhEJE/sHYhRUx6lIeSlAo8lm6BvAbqnbPcE+2Zs4+5JYAhoNLMa4I+BL598qSIi+aWrf5TWhqrQ55s/llxfjP0ScJe7j/y8RmZ2i5l1mFlHb29vjksSEZkdXQUwtBKyC/p9wNIp20uCfTO2MbMoUAf0A2uB/25me4DfA/7UzG6d/gLuvtHd2929vbm5+Xh/BhGRUy6VdnoGxvL+QixkN6nZFmClmbWRCfT1wCentdkMbACeBa4HnnJ3By6fbGBmXwJG3P3rs1C3iEioDhwZJ55K5/0Yesgi6N09GZyFPw5EgPvcfbuZ3QF0uPtm4F5gk5l1AgNkfhmIiBStrv5RIP/H0EOW0xS7+2PAY9P23T7l8TjwiWN8jy+dQH0iInlp7+QY+jwfWgm6M1ZE5IR0DcQojRiL51eGXcoxKehFRE7A3v4YS+qriJTk99BKUNCLiJyQroHRgui2AQW9iMhxc3e6+gpjDD0o6EVEjttgLMHwRFJn9CIixertoZX5P4YeFPQiIsdt70Awa6W6bkREilNXAY2hBwW9iMhx6+qPsbC2nIrSSNilZEVBLyJynPYOjBbEHDeTFPQiIsepqz9WELNWTlLQi4gch9GJJIeGJ/J++cCpFPQiIsfh6Z2HALhkWX3IlWRPQS8ichy+++J+FswrZ+3pjWGXkjUFvYhIloZiCZ7ZeYiPXbi4ICYzm6SgFxHJ0vdfeZNEyll30eKwSzkuCnoRkSxt3raftqZqzm+pC7uU46KgFxHJwsEj4zy7q5/rLlyMWeF024CCXkQkK49u2487XFdg3TaQZdCb2dVmttPMOs3sthmOl5vZQ8Hx58xsebB/jZm9GHxtM7NfnuX6RUROic3b9nNeSy1nNNeEXcpxO2bQm1kEuBu4BlgF3Ghmq6Y1uwkYdPcVwF3AncH+V4B2d78IuBr4ezPLakFyEZF8sbtvlJd6hlh3YUvYpZyQbM7o1wCd7r7L3ePAg8C6aW3WAfcHjx8BrjQzc/eYuyeD/RWAz0bRIiKnypHxBHc98Rpm8NELF4VdzgnJ5uy6Beiest0DrD1aG3dPmtkQ0Aj0mdla4D5gGfDpKcH/FjO7BbgFoLW19Xh/BhGRWTeRTLHp2S6+/nQnh2MJbr6sjUV1lWGXdUJy3o3i7s8B55rZOcD9ZvZ9dx+f1mYjsBGgvb1dZ/0iEqrB0Ti//Lc/Zk9/jMtXNvHHV5/NeQU2pHKqbIJ+H7B0yvaSYN9MbXqCPvg6oH9qA3ffYWYjwHlAxwlXLCKSY99+voc9/TE2fvoSfunc08Iu56Rl00e/BVhpZm1mVgasBzZPa7MZ2BA8vh54yt09eE4UwMyWAWcDe2alchGRHHB3HtrSzerW+UUR8pBF0Ad96rcCjwM7gIfdfbuZ3WFm1wXN7gUazawT+CIwOQTzMmCbmb0I/DPwO+7eN8s/g4jIrHl+72FePzTC+kuXHrtxgciqj97dHwMem7bv9imPx4FPzPC8TcCmk6xRROSUeWjLXqrKIlx7QeHdGHU0ujNWRCQwMpHkey+9yccuWExNefHc8qOgFxEJfG/bfmLxFDesKZ5uG1DQi4i85cEt3axcUMPqpfPDLmVWKehFRICdB4Z5sfswN1y6tOBmpzwWBb2IzHl9IxP8j8d3UhoxfuXiJWGXM+uK52qDiMhxGh5PcM+PdnPPj3Yxlkjxex86k4bqsrDLmnUKehGZM3b1jtDRNcjrB4fZeXCEbd2HGRpL8JHzT+OLV53FigWFNwVxNhT0IlLUeocneHTbfv7vi/t4qWcIgLJoCSsX1PChcxbymfcu48Iiu/g6nYJeRIrO8HiCx7cfZPO2/fy4s49U2jmvpZY/u/Ycrjh7Acsaq4mUFNcF159HQS8iReUrP9jJ3/37LuLJNEsbKvncB0/n4xe1sHLhvLBLC42CXkSKxlAswd3PvMFlK5r4wodWsnrp/KIbKnkiFPQiUjSeee0QqbTzhQ+t5OLW+rDLyRsaRy8iRePJHYdoqinjoiXzwy4lryjoRaQoxJNpntl5iCvOXkDJHLrQmg0FvYgUhS17BhgeT/KhcxaGXUreUdCLSFF4csdByqMlXLayKexS8o6CXkQKnrvz5I6DvH9FE1VlGmMynYJeRAreawdH6B4YU7fNUSjoRaTgPbnjIABXnrMg5EryU1ZBb2ZXm9lOM+s0s9tmOF5uZg8Fx58zs+XB/qvMbKuZvRz8ecUs1y8iwhOvHuTCJXUsrK0Iu5S8dMygN7MIcDdwDbAKuNHMVk1rdhMw6O4rgLuAO4P9fcDH3P18YANaKFxEZtmh4XG29RzmSnXbHFU2Z/RrgE533+XuceBBYN20NuuA+4PHjwBXmpm5+wvuvj/Yvx2oNLPy2ShcRCSddv768ddwR/3zP0c2Qd8CdE/Z7gn2zdjG3ZPAENA4rc2vAs+7+8T0FzCzW8ysw8w6ent7s61dROawRCrN7z/8Ig91dPO5D57BqsW1YZeUt07JxVgzO5dMd85vzXTc3Te6e7u7tzc3N5+KkkSkgI0nUvz2N5/nuy/u5w8/fBa3XXN22CXltWwGnO4Dlk7ZXhLsm6lNj5lFgTqgH8DMlgD/DHzG3d846YpFZE5zdz73za08s7OXO9ady2feuzzskvJeNmf0W4CVZtZmZmXAemDztDabyVxsBbgeeMrd3czmA/8C3ObuP56lmkVkDnvi1YM8s7OXP//oKoV8lo4Z9EGf+63A48AO4GF3325md5jZdUGze4FGM+sEvghMDsG8FVgB3G5mLwZfGugqIicklXb++gev0dZUzYb3Lgu7nIKR1b3C7v4Y8Ni0fbdPeTwOfGKG5/0F8BcnWaOICACPbtvPzoPDfO3G1UQjut8zW3qnRKQgxJNpvvLEa6xaVMu15y8Ku5yCoqAXkYLwcEc3ewdi/OGHz9J888dJQS8ieW8snuJvfvg67cvq+YWzNAT7eGk+TxHJC0//7BAPPLuHkYkkIxMpYvEko8GfsXgKgK/duFqLfZ8ABb2IhO7pnx3ilk0dLJhXwdKGSlrmV1BVFqW6PEp1WYSq8iirFs1j7enTb7iXbCjoRSRUP+7s47e+uZWzTpvHt25+D3WVpWGXVHTURy8ioenYM8DN93fQ1ljNps+uVcjniM7oReSUc3f+T0cPX350O4vqKth08xrqq8vCLqtoKehF5JQ6MDTObd95iWd29rKmrYG/Wb+aBfO0YEguKehFJGfcnad3HmJvf4yB0Th9o3Ee3bafRCrNf/nYKja8d7nGxJ8CCnoRyYlkKs1t33mZR7b2AGAG9VVlXNxaz5evO5flTdUhVzh3KOhFZNaNJ1Lc+o/P8+SOQ/zuFSvY8L7lzK8qI6Kz91Ao6EVkVg3FEtz8wBY6ugb5r+vO5dOaSjh0CnoROSkTyRQv7D3MT3b185Nd/Ty/9zDuztduXM1HL1gcdnmCgl5EjtOR8QR7+kbZ2jXIj17v4ye7+onFU5QYrFpcy2fes4zrLlrMBUvmh12qBBT0IgJkFvXY8eYR9vSP0tUfo6t/lKGxBPFkmngqzehEir0DmdEzk9qaqrn+kiVcvrKZNW0NuuEpTynoRea4wdE4D3d0s+knXfQMjr21v3leOQ1VZZRFSyiLllBTHuXD5y5kWWM1yxurOXdxLUsbqkKsXLKloBeZg9yd5/cO8uBPu9m8bT8TyTRr2hr44lVncs6iWlobqqguVzwUi6z+Js3sauCrQAS4x93/ctrxcuAB4BKgH7jB3feYWSPwCHAp8A13v3U2ixeRny+Vdnb3vbML5vWDwzy0pZvXD41QVRbhVy5ewob3LePs02rDLldy5JhBb2YR4G7gKqAH2GJmm9391SnNbgIG3X2Fma0H7gRuAMaBPwfOC75EJIeSqTQ/fqOff9vZy8v7DvPKviOMJVLvare6dT53/ur5XHvBYmp05l70svkbXgN0uvsuADN7EFgHTA36dcCXgsePAF83M3P3UeA/zGzF7JUsIgCJVJrh8SRHxhIcPDLOv24/wKPb9tM3EqeitIRzF9dxw6VLOa+ljqaaTF97ebSEpppyljXqrtS5JJugbwG6p2z3AGuP1sbdk2Y2BDQCfdkUYWa3ALcAtLa2ZvMUkaI0MBpndCLJeCLFWCJF/0icrv5RugZidA+M0TcywWAszsBInOGJ5DueWxYp4YqzF/Dx1S384tnNlEcjIf0Ukm/y4v9s7r4R2AjQ3t7uIZcjckoMjyfYOxDj5Z4hfrp7gOd2D7Dv8NiMbavKIrQ2VNE8r5zWhioaqsuoryqjrjJKbWUpdZWltC9roK5Kwxvl3bIJ+n3A0inbS4J9M7XpMbMoUEfmoqzInOfudA+MsXXvAFu7Bnm5Z4i9AzEGY4m32jTVlHHp8gZ+433LmV9VSmVZhIpohPrqUlobqmmqKdNaqXLCsgn6LcBKM2sjE+jrgU9Oa7MZ2AA8C1wPPOXuOjOXOa13eIKHO7p5cMteugcyZ+o15VEuWFLHR85fxNKGKlobqjhz4TzOaK5WkEvOHDPogz73W4HHyQyvvM/dt5vZHUCHu28G7gU2mVknMEDmlwEAZrYHqAXKzOzjwC9NG7EjUvA6D42wu2+UgdEJBkYTvLJ/iB9sP0Ai5bz39EZu+cAZtC+r58yF8zSDo5xylm8n3u3t7d7R0RF2GSLHFE+m+f4rb7Lp2S46ugbfcWx+VSm/snoJn1zbyooFNSFVKHOJmW119/aZjuXFxViRQjI4GueBZ7vY9JM99I3EWd5YxZ9dew5r2hqoryqjsaaMytKIumIkbyjoRbLUMxjjnh/t5qEt3YwlUlxx9gI2vG85l69o0nJ4ktcU9CJZeGHvIJ/8h+dIpNKsu6iF3/rg6Zy5cF7YZYlkRUEvcgy7+0a56f4OmueV862b12rGRik4JWEXIJLPeocn2HDfTwG4/7NrFPJSkBT0IkcxNJbgpvu3cGh4nHs3tNPWpPlhpDCp60aETKhv2T3Alq4Bdh4Y5vWDI+w7PEaJwcZPt7O6tT7sEkVOmIJe5qzxRIoHnt3Dd1/cz6tvHsE9MzHYGQtquGRZPesvXcr7VjRxyTKFvBQ2Bb3MOam0853ne7jridfYPzRO+7J6vnDlSta2NbK6dT4VpZr1UYqLgl6KjrszGk9lpvftj7G7b5Te4QmOjCU4Mp5gV+8ou/pGuWBJHX/1axfyvjOawi5ZJKcU9JK3DsfidA+MEYsnGU+mGU+kSKUdd3Cc8USa3X0jvHFolDd6RxgYjTMWzOM+fWaP2ooodVWl1FaUsnh+Jb9/1Zlce/4i3egkc4KCXkIxnkjROzzBwSPj9A5P0DeaWUyjb2SC3X2jvHZwmEPDE8f8PtESY1ljFWc017CmrYGqsgiVpRGqyqMsqa+krama5Y3VWuha5jR9+iVnRiaSvH5wmNeDmR33DsToDr6mzsU+VW1FlGWN1Vy2somzFs5jeVM11WVRKkpLqCiNEI0YhlFiUBopoaW+ktKIRgmL/DwKegEyqx11Hhqh89AIfSNxxuJJYvFMN0gilSaRchKpNGl30ulM14k7pN1JpZ1k2okn08TiKUbjSYbHk/ROOSMvjRgt8ytZ2lDFeecvYnFdBQtqK1hYW0FzTTlNNWXUV5cptEVyQEE/B4zFUxw8Mk7Kg/5td7r6Y7y8b4hX9g3x6ptHeHNo/F3Pm+wGKYuWEI0YpSUllJRkzqYNwwxKzIhGjBIzyiIlNNWU0VpeRU1ZlNbGKlYuqGHlwnksra8kqhAXCYWCvsgcPDLOc7sH2LJ7gNcODrOnf5SDR2bu6zaDM5prWNvWwMqF894K5YW15VREI7pQKVIkFPR5ZnQiya7eUeKpFPGkM5FMMTyeZGgswdBYgrF4KtN9EnSbjExkjh0ZS9A9EGNPfwzILFl31mnzuGxFM21NVSyqqyQayQS3mbGoroJVi2p1kVJkDtC/8jyx//AY3/h/e/in5/YyPJE8arsSg0iJYZbpQqkpj1JbUUptZSlnnTaPX3/PMta0NbBqUa26SkQEUNDnjLvTPxpnd98ou3pH6BkcI5Fy3D24gAmpdJqUO73DEzy54xAAHzl/EdeefxoVQd94ebSEeRWl1FVmvnTXpogcr6yC3syuBr5KZnHwe9z9L6cdLwceAC4B+oEb3H1PcOxPgJuAFPC77v74rFWfQ5N3V/YOTzAYizMUy3SdDE8kSSTTJNOZkSh9IxPsGxxj/9AYB49MMJFIkUg58VSaVPrtu3ZKDKKREkqCC5glZkRKjGiJUR4t4bPvX85vvL+NlvmVIf7UIlKMjhn0ZhYB7gauAnqALWa22d1fndLsJmDQ3VeY2XrgTuAGM1sFrAfOBRYDT5rZme6emu0f5Hik086BI+O8sPcwz+8d5OWeIUYmkkHftzOWSNE3nLnL8liqyiK0zK+kpb6S8xbXvXUmXhoxGqvLOb25mtObamiprySii5siEoJszujXAJ3uvgvAzB4E1gFTg34d8KXg8SPA1y2zMvI64EF3nwB2m1ln8P2enZ3y3/azA0f4T//4wjv2JdPOeHBL/EQicxaeDG6hn1QeLeG8ljoWz698q/+7LFpCc005zfPKaaopp6GmjPlB18m8ilLKIiVEIm+fjWsRaBHJZ9kEfQvQPWW7B1h7tDbunjSzIaAx2P+Tac9tmf4CZnYLcAtAa2trtrW/Q0U0wsqFNe/YFykpoSJaQmVZhPJoCaWREqIlRqSkhPlVpaxunc85i2p1k46IFLW8uBjr7huBjQDt7e1+jOYzWt5Uzd9+6pJZrUtEpBhkcyq7D1g6ZXtJsG/GNmYWBerIXJTN5rkiIpJD2QT9FmClmbWZWRmZi6ubp7XZDGwIHl8PPOXuHuxfb2blZtYGrAR+Ojuli4hINo7ZdRP0ud8KPE5meOV97r7dzO4AOtx9M3AvsCm42DpA5pcBQbuHyVy4TQKfD3vEjYjIXGM+fYWGkLW3t3tHR0fYZYiIFBQz2+ru7TMd03ATEZEip6AXESlyCnoRkSKnoBcRKXJ5dzHWzHqBrpP4Fk1A3yyVU0z0vhyd3puj03tzdPn23ixz9+aZDuRd0J8sM+s42pXnuUzvy9HpvTk6vTdHV0jvjbpuRESKnIJeRKTIFWPQbwy7gDyl9+Xo9N4cnd6boyuY96bo+uhFROSdivGMXkREplDQi4gUuaIJejO72sx2mlmnmd0Wdj1hMrOlZva0mb1qZtvN7AvB/gYze8LMXg/+rA+71jCYWcTMXjCz7wXbbWb2XPDZeSiYjnvOMbP5ZvaImf3MzHaY2Xv1mckws98P/i29Ymb/ZGYVhfS5KYqgn7KA+TXAKuDGYGHyuSoJ/Gd3XwW8B/h88H7cBvzQ3VcCPwy256IvADumbN8J3OXuK4BBMovdz0VfBf7V3c8GLiTzHs35z4yZtQC/C7S7+3lkpmtfTwF9booi6JmygLm7x4HJBcznJHd/092fDx4Pk/kH20LmPbk/aHY/8PFQCgyRmS0BrgXuCbYNuILMovYwd9+XOuADZNaWwN3j7n4YfWYmRYHKYAW9KuBNCuhzUyxBP9MC5u9ahHwuMrPlwGrgOWChu78ZHDoALAyrrhD9T+CPgHSw3QgcdvdksD1XPzttQC/wv4NurXvMrBp9ZnD3fcBfAXvJBPwQsJUC+twUS9DLDMysBvg28HvufmTqsWCpxzk1ttbMPgoccvetYdeSh6LAxcD/cvfVwCjTumnm4mcGILgusY7ML8PFQDVwdahFHadiCXotQj6NmZWSCflvuft3gt0HzWxRcHwRcCis+kLyfuA6M9tDpnvvCjL90vOD/5LD3P3s9AA97v5csP0ImeCf658ZgA8Bu929190TwHfIfJYK5nNTLEGfzQLmc0bQ73wvsMPdvzLl0NRF3DcA3z3VtYXJ3f/E3Ze4+3Iyn5Gn3P1TwNNkFrWHOfi+ALj7AaDbzM4Kdl1JZq3nOf2ZCewF3mNmVcG/rcn3pmA+N0VzZ6yZfYRM/+vkAub/LdyKwmNmlwE/Al7m7b7oPyXTT/8w0EpmKuhfc/eBUIoMmZn9AvAH7v5RMzudzBl+A/AC8OvuPhFieaEws4vIXKQuA3YBv0nmZHDOf2bM7MvADWRGtL0A3EymT74gPjdFE/QiIjKzYum6ERGRo1DQi4gUOQW9iEiRU9CLiBQ5Bb2ISJFT0IuIFDkFvYhIkfv/zJ7WNU0TkdgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 4.55254668e-05, 6.59742230e-05,\n",
       "       3.50191142e-04, 3.61756148e-04, 4.82727339e-04, 5.70521139e-04,\n",
       "       5.95474023e-04, 7.49246668e-04, 7.81936179e-04, 9.73928469e-04,\n",
       "       9.84688837e-04, 1.00152885e-03, 1.57637382e-03, 1.61007471e-03,\n",
       "       1.69565359e-03, 1.70547757e-03, 1.78813170e-03, 2.10240080e-03,\n",
       "       2.28650996e-03, 2.29084421e-03, 2.54667186e-03, 2.75543303e-03,\n",
       "       2.81142826e-03, 2.83841382e-03, 2.84298886e-03, 2.86109571e-03,\n",
       "       2.92043386e-03, 3.13279470e-03, 3.30145369e-03, 3.43080612e-03,\n",
       "       3.53738409e-03, 3.75494566e-03, 3.80010480e-03, 3.80694778e-03,\n",
       "       4.00731790e-03, 4.05752395e-03, 4.24187306e-03, 4.32178324e-03,\n",
       "       5.01881370e-03, 5.33603705e-03, 5.54619634e-03, 6.99232564e-03,\n",
       "       7.58672776e-03, 8.12140555e-03, 8.22419058e-03, 8.74854259e-03,\n",
       "       9.03874121e-03, 9.20653731e-03, 9.51638732e-03, 9.56155073e-03,\n",
       "       9.73678012e-03, 9.84033413e-03, 9.92167378e-03, 1.03807539e-02,\n",
       "       1.06418244e-02, 1.06779865e-02, 1.11795925e-02, 1.17181956e-02,\n",
       "       1.18964876e-02, 1.19313892e-02, 1.21124083e-02, 1.24641120e-02,\n",
       "       1.27835450e-02, 1.39565139e-02, 1.40619693e-02, 1.49204222e-02,\n",
       "       1.62569748e-02, 1.63212580e-02, 1.63806672e-02, 1.88263801e-02,\n",
       "       2.00354490e-02, 2.42553626e-02, 2.47052519e-02, 2.51664085e-02,\n",
       "       2.53840403e-02, 2.60650977e-02, 2.93580588e-02, 3.00537913e-02,\n",
       "       3.37094930e-02, 4.30816044e-02, 4.49839580e-02, 4.63907423e-02,\n",
       "       6.16315187e-02, 6.16444115e-02, 7.16397224e-02])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rf = model_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21276036, -0.17013222,  0.19216261, ..., -0.16317337,\n",
       "         0.24229372, -0.10806679],\n",
       "       [-0.07424421, -0.12804609,  0.05910014, ..., -0.11487924,\n",
       "         0.21340366, -0.00523934],\n",
       "       [-0.07424421, -0.12804609,  0.05910014, ..., -0.11487924,\n",
       "         0.21340366, -0.00523934],\n",
       "       ...,\n",
       "       [-0.07424421, -0.12804609,  0.05910014, ..., -0.11487924,\n",
       "         0.21340366, -0.00523934],\n",
       "       [-0.07424421, -0.12804609,  0.05910014, ..., -0.11487924,\n",
       "         0.21340366, -0.00523934],\n",
       "       [-0.20011401, -0.14221996,  0.15098258, ..., -0.07115534,\n",
       "         0.22269656, -0.00498262]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eval baseline + pred distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare baselines and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FImp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines100 = []\n",
    "for i in range(100):\n",
    "    baseline = pd.read_csv(\"data/2020-11-17_rand_embs_noise\"+str(i)+\".csv\", sep=\",\", index_col=None, header=0, names=None)\n",
    "    baselines100.append(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_bl = []\n",
    "for bl in baselines100:\n",
    "    scores_bl.append(AvCorrCoef(y_test, bl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats import weightstats as stests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_predrf = AvCorrCoef(y_test, preds_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.180866964184471e-05\n",
      "0.0009816309111870146\n",
      "0.1335788484731206\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scores_bl))\n",
    "print(np.std(scores_bl))\n",
    "\n",
    "print(score_predrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "-1353.1346250574434\n",
      "reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "ztest ,pval = stests.ztest(scores_bl, x2=None, value=score_predrf)\n",
    "print(float(pval))\n",
    "print(ztest)\n",
    "if pval<0.05:\n",
    "    print(\"reject null hypothesis\")\n",
    "else:\n",
    "    print(\"accept null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load baselinedata\n",
    "baseline = pd.read_csv(\"data/2020-10-02_baseline.csv\", sep=\",\", index_col=None, names=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.183330</td>\n",
       "      <td>-0.338543</td>\n",
       "      <td>0.394645</td>\n",
       "      <td>0.208696</td>\n",
       "      <td>0.272407</td>\n",
       "      <td>0.262314</td>\n",
       "      <td>0.176081</td>\n",
       "      <td>0.452315</td>\n",
       "      <td>-0.088711</td>\n",
       "      <td>-0.156307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093218</td>\n",
       "      <td>0.102018</td>\n",
       "      <td>0.116440</td>\n",
       "      <td>-0.374251</td>\n",
       "      <td>-0.039406</td>\n",
       "      <td>-0.588085</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>-0.034762</td>\n",
       "      <td>0.147428</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.198364</td>\n",
       "      <td>-0.138444</td>\n",
       "      <td>0.031957</td>\n",
       "      <td>-0.132682</td>\n",
       "      <td>0.392281</td>\n",
       "      <td>-0.027410</td>\n",
       "      <td>-0.210383</td>\n",
       "      <td>0.430158</td>\n",
       "      <td>-0.022197</td>\n",
       "      <td>0.300843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025187</td>\n",
       "      <td>-0.009398</td>\n",
       "      <td>-0.151384</td>\n",
       "      <td>-0.085963</td>\n",
       "      <td>0.343738</td>\n",
       "      <td>-0.428683</td>\n",
       "      <td>-0.063570</td>\n",
       "      <td>-0.115330</td>\n",
       "      <td>-0.050759</td>\n",
       "      <td>-0.008490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.080653</td>\n",
       "      <td>-0.022944</td>\n",
       "      <td>0.170160</td>\n",
       "      <td>0.222607</td>\n",
       "      <td>-0.033463</td>\n",
       "      <td>0.099859</td>\n",
       "      <td>0.325499</td>\n",
       "      <td>0.135997</td>\n",
       "      <td>0.050320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106332</td>\n",
       "      <td>-0.312108</td>\n",
       "      <td>0.053406</td>\n",
       "      <td>-0.329611</td>\n",
       "      <td>0.262430</td>\n",
       "      <td>-0.467402</td>\n",
       "      <td>0.022986</td>\n",
       "      <td>0.059246</td>\n",
       "      <td>0.192895</td>\n",
       "      <td>-0.357010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.088568</td>\n",
       "      <td>-0.089175</td>\n",
       "      <td>0.358509</td>\n",
       "      <td>0.088131</td>\n",
       "      <td>0.491026</td>\n",
       "      <td>-0.221425</td>\n",
       "      <td>0.074407</td>\n",
       "      <td>0.517344</td>\n",
       "      <td>-0.409624</td>\n",
       "      <td>-0.197844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068139</td>\n",
       "      <td>0.097460</td>\n",
       "      <td>-0.080508</td>\n",
       "      <td>-0.232688</td>\n",
       "      <td>-0.128343</td>\n",
       "      <td>-0.240722</td>\n",
       "      <td>0.304749</td>\n",
       "      <td>-0.078456</td>\n",
       "      <td>-0.203725</td>\n",
       "      <td>0.140829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.310554</td>\n",
       "      <td>-0.041779</td>\n",
       "      <td>0.199236</td>\n",
       "      <td>0.038224</td>\n",
       "      <td>0.242709</td>\n",
       "      <td>-0.190991</td>\n",
       "      <td>-0.492122</td>\n",
       "      <td>0.290447</td>\n",
       "      <td>0.209475</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038870</td>\n",
       "      <td>0.077799</td>\n",
       "      <td>0.122043</td>\n",
       "      <td>0.183782</td>\n",
       "      <td>0.312981</td>\n",
       "      <td>-0.260714</td>\n",
       "      <td>-0.365845</td>\n",
       "      <td>-0.090030</td>\n",
       "      <td>0.364407</td>\n",
       "      <td>0.203804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>-0.035068</td>\n",
       "      <td>-0.101342</td>\n",
       "      <td>-0.038527</td>\n",
       "      <td>-0.515978</td>\n",
       "      <td>0.422511</td>\n",
       "      <td>-0.035562</td>\n",
       "      <td>-0.140601</td>\n",
       "      <td>0.393623</td>\n",
       "      <td>0.059193</td>\n",
       "      <td>0.195277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041091</td>\n",
       "      <td>-0.124184</td>\n",
       "      <td>0.012155</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>-0.036674</td>\n",
       "      <td>0.065368</td>\n",
       "      <td>0.021741</td>\n",
       "      <td>-0.214591</td>\n",
       "      <td>0.231099</td>\n",
       "      <td>-0.124138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>-0.445690</td>\n",
       "      <td>-0.025927</td>\n",
       "      <td>0.397435</td>\n",
       "      <td>0.450872</td>\n",
       "      <td>0.467972</td>\n",
       "      <td>-0.463584</td>\n",
       "      <td>-0.308271</td>\n",
       "      <td>0.145245</td>\n",
       "      <td>0.075171</td>\n",
       "      <td>0.117758</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.158808</td>\n",
       "      <td>-0.019649</td>\n",
       "      <td>0.467825</td>\n",
       "      <td>-0.628538</td>\n",
       "      <td>0.172530</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>0.297175</td>\n",
       "      <td>0.106137</td>\n",
       "      <td>-0.103812</td>\n",
       "      <td>-0.019936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>0.013183</td>\n",
       "      <td>-0.134107</td>\n",
       "      <td>-0.160256</td>\n",
       "      <td>-0.159644</td>\n",
       "      <td>0.420977</td>\n",
       "      <td>0.159681</td>\n",
       "      <td>-0.192252</td>\n",
       "      <td>0.340523</td>\n",
       "      <td>-0.044632</td>\n",
       "      <td>-0.207104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057211</td>\n",
       "      <td>0.136079</td>\n",
       "      <td>-0.130153</td>\n",
       "      <td>-0.338041</td>\n",
       "      <td>0.330491</td>\n",
       "      <td>-0.188173</td>\n",
       "      <td>-0.160723</td>\n",
       "      <td>-0.170621</td>\n",
       "      <td>0.366945</td>\n",
       "      <td>0.061022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>-0.682124</td>\n",
       "      <td>-0.276185</td>\n",
       "      <td>0.089449</td>\n",
       "      <td>0.211166</td>\n",
       "      <td>0.439895</td>\n",
       "      <td>-0.219995</td>\n",
       "      <td>0.308842</td>\n",
       "      <td>0.747637</td>\n",
       "      <td>-0.006205</td>\n",
       "      <td>0.247991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231789</td>\n",
       "      <td>0.061435</td>\n",
       "      <td>0.391486</td>\n",
       "      <td>-0.378326</td>\n",
       "      <td>0.034358</td>\n",
       "      <td>-0.311263</td>\n",
       "      <td>0.024432</td>\n",
       "      <td>-0.245886</td>\n",
       "      <td>0.068491</td>\n",
       "      <td>0.264692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>-0.010903</td>\n",
       "      <td>0.194169</td>\n",
       "      <td>-0.036732</td>\n",
       "      <td>-0.023183</td>\n",
       "      <td>0.267444</td>\n",
       "      <td>0.016398</td>\n",
       "      <td>-0.244801</td>\n",
       "      <td>0.479853</td>\n",
       "      <td>0.018255</td>\n",
       "      <td>0.393766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.250467</td>\n",
       "      <td>-0.235702</td>\n",
       "      <td>0.203558</td>\n",
       "      <td>-0.381977</td>\n",
       "      <td>0.204990</td>\n",
       "      <td>-0.007998</td>\n",
       "      <td>0.121227</td>\n",
       "      <td>-0.000897</td>\n",
       "      <td>0.282391</td>\n",
       "      <td>-0.296145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -0.183330 -0.338543  0.394645  0.208696  0.272407  0.262314  0.176081   \n",
       "1    -0.198364 -0.138444  0.031957 -0.132682  0.392281 -0.027410 -0.210383   \n",
       "2     0.010989  0.080653 -0.022944  0.170160  0.222607 -0.033463  0.099859   \n",
       "3     0.088568 -0.089175  0.358509  0.088131  0.491026 -0.221425  0.074407   \n",
       "4    -0.310554 -0.041779  0.199236  0.038224  0.242709 -0.190991 -0.492122   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1235 -0.035068 -0.101342 -0.038527 -0.515978  0.422511 -0.035562 -0.140601   \n",
       "1236 -0.445690 -0.025927  0.397435  0.450872  0.467972 -0.463584 -0.308271   \n",
       "1237  0.013183 -0.134107 -0.160256 -0.159644  0.420977  0.159681 -0.192252   \n",
       "1238 -0.682124 -0.276185  0.089449  0.211166  0.439895 -0.219995  0.308842   \n",
       "1239 -0.010903  0.194169 -0.036732 -0.023183  0.267444  0.016398 -0.244801   \n",
       "\n",
       "           7         8         9    ...       758       759       760  \\\n",
       "0     0.452315 -0.088711 -0.156307  ...  0.093218  0.102018  0.116440   \n",
       "1     0.430158 -0.022197  0.300843  ...  0.025187 -0.009398 -0.151384   \n",
       "2     0.325499  0.135997  0.050320  ...  0.106332 -0.312108  0.053406   \n",
       "3     0.517344 -0.409624 -0.197844  ...  0.068139  0.097460 -0.080508   \n",
       "4     0.290447  0.209475  0.507692  ... -0.038870  0.077799  0.122043   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1235  0.393623  0.059193  0.195277  ...  0.041091 -0.124184  0.012155   \n",
       "1236  0.145245  0.075171  0.117758  ... -0.158808 -0.019649  0.467825   \n",
       "1237  0.340523 -0.044632 -0.207104  ... -0.057211  0.136079 -0.130153   \n",
       "1238  0.747637 -0.006205  0.247991  ... -0.231789  0.061435  0.391486   \n",
       "1239  0.479853  0.018255  0.393766  ... -0.250467 -0.235702  0.203558   \n",
       "\n",
       "           761       762       763       764       765       766       767  \n",
       "0    -0.374251 -0.039406 -0.588085  0.001833 -0.034762  0.147428  0.430758  \n",
       "1    -0.085963  0.343738 -0.428683 -0.063570 -0.115330 -0.050759 -0.008490  \n",
       "2    -0.329611  0.262430 -0.467402  0.022986  0.059246  0.192895 -0.357010  \n",
       "3    -0.232688 -0.128343 -0.240722  0.304749 -0.078456 -0.203725  0.140829  \n",
       "4     0.183782  0.312981 -0.260714 -0.365845 -0.090030  0.364407  0.203804  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1235 -0.116769 -0.036674  0.065368  0.021741 -0.214591  0.231099 -0.124138  \n",
       "1236 -0.628538  0.172530  0.004418  0.297175  0.106137 -0.103812 -0.019936  \n",
       "1237 -0.338041  0.330491 -0.188173 -0.160723 -0.170621  0.366945  0.061022  \n",
       "1238 -0.378326  0.034358 -0.311263  0.024432 -0.245886  0.068491  0.264692  \n",
       "1239 -0.381977  0.204990 -0.007998  0.121227 -0.000897  0.282391 -0.296145  \n",
       "\n",
       "[1240 rows x 768 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FImp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred\n",
    "mse_pred = MeanSqErr(y_test, preds_rf)\n",
    "mse_baseline = MeanSqErr(y_test, baselinedata)\n",
    "(mse_baseline, mse_pred, MeanSqErr(y_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# btw -1, +1 (coef correl)\n",
    "avcorref_pred = AvCorrCoef(y_test, preds_rf)\n",
    "avcorref_baseline = AvCorrCoef(y_test, baselinedata)\n",
    "(avcorref_baseline, avcorref_pred, AvCorrCoef(y_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avrelerr_pred = AvRelErr(y_test, preds_rf)\n",
    "avrelerr_baseline = AvRelErr(y_test, baselinedata)\n",
    "( avrelerr_baseline, avrelerr_pred, AvRelErr(y_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avrootmeansqerr_pred = AvRootMeanSqErr(y_test, preds_rf)\n",
    "avrootmeansqerr_baseline = AvRootMeanSqErr(y_test, baselinedata)\n",
    "(avrootmeansqerr_baseline, avrootmeansqerr_pred, AvRootMeanSqErr(y_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avrelrootmeansqerr_pred = AvRelRootMeanSqErr(y_test, preds_rf)\n",
    "avrelrootmeansqerr_baseline = AvRelRootMeanSqErr(y_test, baselinedata)\n",
    "avrelrootmeansqerr_opti = AvRelRootMeanSqErr(y_test, y_test)\n",
    "\n",
    "\n",
    "(avrelrootmeansqerr_baseline, avrelrootmeansqerr_pred, avrelrootmeansqerr_opti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselinedata = baseline.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with optiRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FImp import optiRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti_model = optiRF(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.sort(model_rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features names in right order\n",
    "names = ['Same-Unit', 'elaboration-additional-e', 'List', 'elaboration-object-attribute-e',\n",
    "                'condition', 'attribution', 'elaboration-additional', 'circumstance',\n",
    "                'purpose', 'elaboration-general-specific', 'restatement-e', 'reason',\n",
    "                'elaboration-part-whole-e', 'rhetorical-question', 'manner', 'concession',\n",
    "                'consequence-n', 'temporal-same-time', 'restatement', 'elaboration-object-attribute',\n",
    "                'antithesis', 'consequence-s', 'definition', 'Contrast', 'result', 'means', 'attribution-n',\n",
    "                'interpretation-s', 'temporal-after', 'example-e', 'result-e', 'explanation-argumentative',\n",
    "                'elaboration-general-specific-e', 'elaboration-set-member-e', 'attribution-e',\n",
    "                'evaluation-s', 'circumstance-e', 'background', 'evidence', 'comment-e', 'purpose-e',\n",
    "                'interpretation-n', 'condition-e', 'temporal-before', 'comment', 'elaboration-part-whole',\n",
    "                'comparison', 'contingency', 'hypothetical', 'analogy-e', 'evaluation-s-e',\n",
    "                'elaboration-set-member', 'temporal-after-e', 'comparison-e', 'means-e', 'example',\n",
    "                'evidence-e', 'cause', 'preference', 'enablement', 'question-answer-s',\n",
    "                'explanation-argumentative-e', 'definition-e', 'antithesis-e', 'summary-n',\n",
    "                'analogy', 'interpretation-s-e', 'concession-e', 'consequence-s-e', 'manner-e',\n",
    "                'preference-e', 'reason-e', 'temporal-same-time-e', 'consequence-n-e',\n",
    "                'enablement-e', 'evaluation-n', 'temporal-before-e', 'otherwise', 'question-answer-n',\n",
    "                'conclusion', 'dr_exist', 'nb_distinct_rel', 'nb_nuc', 'nb_sat', 'nb_root'\n",
    "                'width', \"height\", \"multinuc\"]\n",
    "\n",
    "len(names)\n",
    "\n",
    "feat_imp = model_rf.feature_importances_\n",
    "    \n",
    "sVals = sorted(feat_imp)  \n",
    "Z = [x for _,x in sorted(zip(feat_imp,names))]\n",
    "for feat, name in zip(sVals, Z):\n",
    "    print(str(feat)+\"  \"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.sort(model_rf.feature_importances_)\n",
    "plt.plot(l)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rf = model_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FImp import rsqq, rsq, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_dists = []\n",
    "rsq_dists = []\n",
    "mse_dists = []\n",
    "\n",
    "for true, pred in zip(preds_rf, y_test):\n",
    "    cos_dists.append(distance.cosine(true, pred))\n",
    "    rsq_dists.append(rsqq(true, pred))\n",
    "    mse_dists.append(mse(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(rsq_dists))\n",
    "print(np.mean(rsq_dists))\n",
    "print(np.max(rsq_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(rsq_dists))\n",
    "print(np.mean(rsq_dists))\n",
    "print(np.max(rsq_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(cos_dists))\n",
    "print(np.mean(cos_dists))\n",
    "print(np.max(cos_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(mse_dists))\n",
    "print(np.mean(mse_dists))\n",
    "print(np.max(mse_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in zip(preds_rf[0], y_test[0]):\n",
    "    print(str(x)+\"   \"+str(float(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_dists = []\n",
    "rsq_dists = []\n",
    "\n",
    "\n",
    "for true, pred in zip(preds_rf, y_test):\n",
    "    #cos_dists.append(distance.cosine(true, pred))\n",
    "    rsq_dists.append(rsqq(true, pred))\n",
    "\n",
    "\n",
    "print(np.min(rsq_dists))\n",
    "print(np.mean(rsq_dists))\n",
    "print(np.max(rsq_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FImp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X = net(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X = pred_X.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mse = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in zip(y_test, pred_X):\n",
    "    x = [int(b) for b in x]\n",
    "    y = [int(a) for a in y]\n",
    "    cur_mse = mse(list(x), list(y))\n",
    "    mean_mse.append(cur_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mae = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in zip(y_test, pred_X):\n",
    "    x = [int(b) for b in x]\n",
    "    y = [int(a) for a in y]\n",
    "    cur_mae = mae(list(x), list(y))\n",
    "    mean_mae.append(cur_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(mean_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(mean_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(mean_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(mean_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbg_pred = pred_X[100]\n",
    "dbg_true = y_test[100]\n",
    "\n",
    "\n",
    "print(mse(dbg_pred, dbg_true))\n",
    "print(\"===============\")\n",
    "for x, y in zip(dbg_pred, dbg_true):\n",
    "    print(str(x)+ \"\\t\"+ str(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_movesdist",
   "language": "python",
   "name": "venv_movesdist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
